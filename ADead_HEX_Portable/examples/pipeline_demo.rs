// ADead-BIB HEX - Pipeline Demo
// Shows real pipeline optimization: Preprocess â†’ VectorAdd â†’ Reduce â†’ Postprocess
// "CUDA gives power. ADead-BIB gives judgment."

use adead_hex_gpu_governor::{
    GpuDispatcher, 
    DataLocation, 
    operations,
    ExecutionTarget,
};

fn main() {
    println!();
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  ADead-BIB HEX - Pipeline Demo                               â•‘");
    println!("â•‘  Real Pipeline: Preprocess â†’ Compute â†’ Reduce â†’ Postprocess  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    let mut dispatcher = GpuDispatcher::new();
    let n = 500_000; // 500K elements

    // ========================================================================
    // SCENARIO A: CUDA Naive (Always GPU, transfer every time)
    // ========================================================================
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("  SCENARIO A: CUDA Naive (Always GPU)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    let mut naive_total_time = 0.0;
    let mut naive_transfers = 0;

    // Step 1: Preprocess (small, should be CPU)
    let preprocess = operations::vector_add(10_000, DataLocation::Host, false);
    naive_total_time += preprocess.estimate_h2d_us() * 2.0 + preprocess.estimate_kernel_us();
    naive_transfers += 2;
    println!("  Step 1: Preprocess (10K) â†’ GPU forced");
    println!("    Time: {:.1} Âµs, Transfers: 2", preprocess.estimate_h2d_us() * 2.0 + preprocess.estimate_kernel_us());

    // Step 2: VectorAdd (large)
    let vectoradd = operations::vector_add(n, DataLocation::Host, false);
    naive_total_time += vectoradd.estimate_h2d_us() * 2.0 + vectoradd.estimate_kernel_us();
    naive_transfers += 2;
    println!("  Step 2: VectorAdd (500K) â†’ GPU forced");
    println!("    Time: {:.1} Âµs, Transfers: 2", vectoradd.estimate_h2d_us() * 2.0 + vectoradd.estimate_kernel_us());

    // Step 3: SAXPY
    let saxpy = operations::saxpy(n, DataLocation::Host, false);
    naive_total_time += saxpy.estimate_h2d_us() * 2.0 + saxpy.estimate_kernel_us();
    naive_transfers += 2;
    println!("  Step 3: SAXPY (500K) â†’ GPU forced");
    println!("    Time: {:.1} Âµs, Transfers: 2", saxpy.estimate_h2d_us() * 2.0 + saxpy.estimate_kernel_us());

    // Step 4: Reduce
    let reduce = operations::reduction(n, DataLocation::Host);
    naive_total_time += reduce.estimate_h2d_us() * 2.0 + reduce.estimate_kernel_us();
    naive_transfers += 2;
    println!("  Step 4: Reduce (500K) â†’ GPU forced");
    println!("    Time: {:.1} Âµs, Transfers: 2", reduce.estimate_h2d_us() * 2.0 + reduce.estimate_kernel_us());

    // Step 5: Postprocess (small)
    let postprocess = operations::vector_add(5_000, DataLocation::Host, false);
    naive_total_time += postprocess.estimate_h2d_us() * 2.0 + postprocess.estimate_kernel_us();
    naive_transfers += 2;
    println!("  Step 5: Postprocess (5K) â†’ GPU forced");
    println!("    Time: {:.1} Âµs, Transfers: 2", postprocess.estimate_h2d_us() * 2.0 + postprocess.estimate_kernel_us());

    println!();
    println!("  NAIVE TOTAL: {:.1} Âµs, {} transfers", naive_total_time, naive_transfers);

    // ========================================================================
    // SCENARIO B: ADead-BIB Governor (Smart decisions)
    // ========================================================================
    println!();
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("  SCENARIO B: ADead-BIB Governor (Smart Decisions)");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    let mut smart_total_time = 0.0;
    let mut smart_transfers = 0;

    // Step 1: Preprocess (small) â†’ CPU
    let preprocess = operations::vector_add(10_000, DataLocation::Host, false);
    let (target1, _) = dispatcher.decide(&preprocess);
    if target1 == ExecutionTarget::CPU {
        smart_total_time += preprocess.estimate_cpu_us();
        println!("  Step 1: Preprocess (10K) â†’ CPU âœ“");
        println!("    Time: {:.1} Âµs, Transfers: 0", preprocess.estimate_cpu_us());
    }

    // Step 2: VectorAdd (large, persist) â†’ GPU with transfer
    let vectoradd = operations::vector_add(n, DataLocation::Host, true);
    let (target2, _) = dispatcher.decide(&vectoradd);
    if matches!(target2, ExecutionTarget::GPUWithTransfer) {
        smart_total_time += vectoradd.estimate_h2d_us() + vectoradd.estimate_kernel_us();
        smart_transfers += 1; // Only H2D, data persists
        println!("  Step 2: VectorAdd (500K) â†’ GPU + Persist âœ“");
        println!("    Time: {:.1} Âµs, Transfers: 1 (H2D only)", vectoradd.estimate_h2d_us() + vectoradd.estimate_kernel_us());
    }

    // Step 3: SAXPY (data already on GPU)
    let saxpy = operations::saxpy(n, DataLocation::Device, true);
    let (target3, _) = dispatcher.decide(&saxpy);
    if target3 == ExecutionTarget::GPU {
        smart_total_time += saxpy.estimate_kernel_us();
        println!("  Step 3: SAXPY (500K) â†’ GPU (data resident) âœ“");
        println!("    Time: {:.1} Âµs, Transfers: 0", saxpy.estimate_kernel_us());
    }

    // Step 4: Reduce (data on GPU)
    let reduce = operations::reduction(n, DataLocation::Device);
    let (target4, _) = dispatcher.decide(&reduce);
    if target4 == ExecutionTarget::GPU {
        smart_total_time += reduce.estimate_kernel_us();
        println!("  Step 4: Reduce (500K) â†’ GPU (data resident) âœ“");
        println!("    Time: {:.1} Âµs, Transfers: 0", reduce.estimate_kernel_us());
    }

    // Step 5: Postprocess (small) â†’ CPU, need D2H
    let postprocess = operations::vector_add(5_000, DataLocation::Host, false);
    let (target5, _) = dispatcher.decide(&postprocess);
    if target5 == ExecutionTarget::CPU {
        // Need to bring data back from GPU first
        let d2h_time = vectoradd.estimate_h2d_us(); // Approximate D2H
        smart_total_time += d2h_time + postprocess.estimate_cpu_us();
        smart_transfers += 1; // D2H
        println!("  Step 5: Postprocess (5K) â†’ CPU (after D2H) âœ“");
        println!("    Time: {:.1} Âµs, Transfers: 1 (D2H)", d2h_time + postprocess.estimate_cpu_us());
    }

    println!();
    println!("  SMART TOTAL: {:.1} Âµs, {} transfers", smart_total_time, smart_transfers);

    // ========================================================================
    // COMPARISON
    // ========================================================================
    println!();
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  COMPARISON                                                  â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!("â•‘                                                              â•‘");
    println!("â•‘  Scenario A: CUDA Naive                                      â•‘");
    println!("â•‘    Total time:  {:>10.1} Âµs                               â•‘", naive_total_time);
    println!("â•‘    Transfers:   {:>10}                                   â•‘", naive_transfers);
    println!("â•‘                                                              â•‘");
    println!("â•‘  Scenario B: ADead-BIB Governor                              â•‘");
    println!("â•‘    Total time:  {:>10.1} Âµs                               â•‘", smart_total_time);
    println!("â•‘    Transfers:   {:>10}                                   â•‘", smart_transfers);
    println!("â•‘                                                              â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    
    let speedup = naive_total_time / smart_total_time;
    let transfer_reduction = ((naive_transfers - smart_transfers) as f64 / naive_transfers as f64) * 100.0;
    
    println!("â•‘  ğŸ”¥ EFFICIENCY GAIN: {:.1}x faster                           â•‘", speedup);
    println!("â•‘  ğŸ”¥ TRANSFER REDUCTION: {:.0}%                               â•‘", transfer_reduction);
    println!("â•‘                                                              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    println!();
    println!("  \"This is SYSTEM optimization, not benchmark optimization.\"");
    println!();
}
